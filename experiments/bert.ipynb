{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JQU-evlhdMNu",
    "outputId": "506d03db-6dde-40b4-96be-f6cd7635f3ab"
   },
   "outputs": [],
   "source": [
    "#!pip install pytorch-pretrained-bert\n",
    "#!pip install fast-bert\n",
    "#!pip install tensorboardX\n",
    "#!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "C1Eqn1fGAxJ2",
    "outputId": "bd594c4f-5d79-44c7-b0c0-6bae64200537"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/NVIDIA/apex\n",
    "#%cd apex\n",
    "#!ls\n",
    "#!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
    "#%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YSWjeDbakMWN"
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForPreTraining, BertConfig, BertForMaskedLM, BertForSequenceClassification\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from fast_bert.prediction import BertClassificationPredictor\n",
    "\n",
    "from fastai.text import Tokenizer, Vocab\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import apex\n",
    "import re\n",
    "\n",
    "import datetime\n",
    "    \n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "\n",
    "from fast_bert.modeling import BertForMultiLabelSequenceClassification\n",
    "from fast_bert.data_cls import BertDataBunch, InputExample, InputFeatures, MultiLabelTextProcessor, convert_examples_to_features\n",
    "from fast_bert.learner_cls import BertLearner\n",
    "from fast_bert.metrics import accuracy_multilabel, accuracy_thresh, fbeta, roc_auc\n",
    "from sklearn.metrics import classification_report, hamming_loss, roc_auc_score\n",
    "\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46-8UWXySPDQ"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oYQJi2j5SS41"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "itVUcAwDCnCP",
    "outputId": "0ac265f0-9c06-473e-dd74-9436b6b0a981"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../datasets\")\n",
    "CROSS_FOLDS = Path(\"../datasets/cross_validation/\")\n",
    "BERT_DATA_PATH = Path(\"data/\")\n",
    "BERT_PATH = Path(\".\")\n",
    "LABEL_PATH = Path(\".\")\n",
    "LOG_PATH = Path(\"logs/\")\n",
    "OUTPUT_PATH = Path(\"models/\")\n",
    "\n",
    "model_state_dict = None\n",
    "LOG_PATH.mkdir(exist_ok=True)\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbP7LLn9uOgy"
   },
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxWS107suLk9"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"run_text\": \"multilabel sdgs with freezable layers - more epochs\",\n",
    "    \"train_size\": -1,\n",
    "    \"val_size\": -1,\n",
    "    \"log_path\": BERT_PATH,\n",
    "    \"full_data_dir\": DATA_PATH,\n",
    "    \"data_dir\": DATA_PATH,\n",
    "    \"task_name\": \"final-3epochs\",\n",
    "    \"no_cuda\": False,\n",
    "    \"bert_model\": 'bert-large-uncased', \n",
    "    \"output_dir\": OUTPUT_PATH,\n",
    "    \"max_seq_length\": 512, \n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 4,\n",
    "    \"eval_batch_size\": 4,\n",
    "    \"learning_rate\": 1e-3, #1e-3 with three epochs, 0.07 loss\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"warmup_proportion\": 0.1,\n",
    "    \"local_rank\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimize_on_cpu\": False,\n",
    "    \"fp16\": True,\n",
    "    \"loss_scale\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3_va60WUFfu"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logfile = str(BERT_PATH/'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(logfile),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "65_P6HwpUHXB",
    "outputId": "41f280bc-e872-4401-fd15-6fd86a85d5ff"
   },
   "outputs": [],
   "source": [
    "#logger.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8S766_HU2fl"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    multi_gpu = True\n",
    "else:\n",
    "    multi_gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cross validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxE6HZCrghnp"
   },
   "outputs": [],
   "source": [
    "labels_index = [str(i) for i in range(1,18)]\n",
    "\n",
    "\"\"\"\n",
    "data_df = pd.read_csv(os.path.join(DATA_PATH, 'cleanup_labelled.csv'))\n",
    "data_df.labels = data_df.labels.str.split('|').apply(lambda x: [int(i) for i in x])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "pattern = r\"(indicator)(\\s+\\d+\\.[\\d+a-d]\\.\\d+)|(target)(\\s+\\d+\\.[\\d+a-d])|(sdgs|sdg|goals|goal)\\W*\\s+(,?\\s*\\b\\d{1,2}\\b[and\\s\\b\\d{1,2}\\b]*)\"\n",
    "masked_df = data_df.text.str.replace(pattern, ' SDGLABEL ', regex=True, flags=re.IGNORECASE)\n",
    "masked_df = pd.DataFrame(masked_df.str.replace('  ', ' ', regex=True, flags=re.IGNORECASE))\n",
    "\n",
    "x = masked_df[['text']].values # text\n",
    "y = mlb.fit_transform(data_df.labels) # labels\n",
    "\n",
    "columns = ['text'] + labels_index\n",
    "\n",
    "for fold in os.listdir(CROSS_FOLDS):\n",
    "    print(f\"Creating {fold}\")\n",
    "    train_index = np.load(f\"{CROSS_FOLDS}/{fold}/train.npy\")\n",
    "    val_index = np.load(f\"{CROSS_FOLDS}/{fold}/val.npy\")\n",
    "    test_index = np.load(f\"{CROSS_FOLDS}/{fold}/test.npy\")\n",
    "    \n",
    "    x_train, x_val, x_test = x[train_index], x[val_index], x[test_index]\n",
    "    y_train, y_val, y_test = y[train_index], y[val_index], y[test_index]\n",
    "    \n",
    "    train = pd.DataFrame(np.hstack((x_train, y_train)))\n",
    "    val = pd.DataFrame(np.hstack((x_val, y_val)))\n",
    "    test = pd.DataFrame(np.hstack((x_test, y_test)))\n",
    "    \n",
    "    fold_dir = Path(BERT_DATA_PATH/fold)\n",
    "    fold_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for split, name in [(train, \"train\"), (val, \"val\"), (test, \"test\")]:\n",
    "        split.columns = columns\n",
    "        split.to_csv(fold_dir/f'{name}_masked.csv')\n",
    "        \n",
    "print('Finished creating all cross validation sets.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8WOwi-27cNL"
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "#metrics.append({'name': 'accuracy_thresh', 'function': accuracy_thresh})\n",
    "#metrics.append({'name': 'roc_auc', 'function': roc_auc})\n",
    "#metrics.append({'name': 'fbeta', 'function': fbeta})\n",
    "metrics.append({'name': 'accuracy_single', 'function': accuracy_multilabel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eIR1w6QXaCb"
   },
   "outputs": [],
   "source": [
    "is_masked = \"\"\n",
    "output_dir = OUTPUT_PATH/args['task_name']\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for fold in sorted(os.listdir(BERT_DATA_PATH)):\n",
    "    if fold.startswith(\"fold_5\"):\n",
    "        print(f\"Processing {fold} {is_masked}\")\n",
    "\n",
    "        fold_dir = output_dir/fold\n",
    "        fold_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        databunch = BertDataBunch(data_dir=BERT_DATA_PATH/fold, \n",
    "                                  label_dir=LABEL_PATH, \n",
    "                                  tokenizer=args['bert_model'], \n",
    "                                  train_file=f'train{is_masked}.csv', \n",
    "                                  val_file=f'val{is_masked}.csv',\n",
    "                                  test_data=None,\n",
    "                                  text_col=\"text\", \n",
    "                                  label_col=labels_index,\n",
    "                                  batch_size_per_gpu=args['train_batch_size'], \n",
    "                                  max_seq_length=args['max_seq_length'], \n",
    "                                  multi_gpu=multi_gpu, \n",
    "                                  multi_label=True, \n",
    "                                  model_type='bert')\n",
    "\n",
    "        learner = BertLearner.from_pretrained_model(databunch, \n",
    "                                                pretrained_path=args['bert_model'], \n",
    "                                                metrics=metrics, \n",
    "                                                device=device, \n",
    "                                                logger=logger, \n",
    "                                                finetuned_wgts_path=None, \n",
    "                                                warmup_steps=500,\n",
    "                                                output_dir=fold_dir,\n",
    "                                                is_fp16=args['fp16'],\n",
    "                                                loss_scale=args['loss_scale'],\n",
    "                                                multi_gpu=multi_gpu,  \n",
    "                                                multi_label=True,\n",
    "                                                logging_steps=50)\n",
    "        learner.fit(args['num_train_epochs'], lr=args['learning_rate'], schedule_type=\"warmup_linear\")\n",
    "        learner.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_avg(models_testx_testy, labels_, thres=0.3):\n",
    "    def calc(model, test_x, test_y):\n",
    "        texts = [x[0] for x in test_x]\n",
    "        predictions = model.predict_batch(texts)\n",
    "        \n",
    "        converted_preds = []\n",
    "        for row in predictions:\n",
    "            row_scores = sorted(row, key=lambda i: (int(i[0])))\n",
    "            final = [y for x,y in row_scores]\n",
    "            converted_preds.append(final)\n",
    "        \n",
    "        preds = np.array(converted_preds)>thres\n",
    "        metrics = classification_report(test_y, preds, target_names=labels_, output_dict=True)\n",
    "        metrics_df = pd.DataFrame.from_dict(metrics)\n",
    "        h = hamming_loss(test_y, preds)\n",
    "        roc = roc_auc_score(test_y, preds, average='micro')\n",
    "        return metrics_df, h, roc\n",
    "\n",
    "    count = 0\n",
    "    model_1, test_x_first, test_y_first = models_testx_testy[0]\n",
    "    metrics_agg, ham, roc = calc(model_1, test_x_first, test_y_first)\n",
    "    n = len(models_testx_testy)\n",
    "\n",
    "    for model, test_x, test_y in models_testx_testy[1:]:\n",
    "        metrics, h, r = calc(model, test_x, test_y)\n",
    "        metrics_agg += metrics\n",
    "        ham += h\n",
    "        roc += r\n",
    "        count +=1\n",
    "        print(count)\n",
    "\n",
    "    return metrics_agg/n, ham/n, roc/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_models = []\n",
    "data_df = pd.read_csv(os.path.join(DATA_PATH, 'cleanup_labelled.csv'))\n",
    "data_df.labels = data_df.labels.str.split('|').apply(lambda x: [int(i) for i in x])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "x = data_df[['text']].values # text\n",
    "y = mlb.fit_transform(data_df.labels) # labels\n",
    "\n",
    "\n",
    "for fold in sorted(os.listdir(OUTPUT_PATH/f\"{args['task_name']}\")):\n",
    "    if fold.startswith(\"fold\"):\n",
    "        print(f\"Processing {fold}\")\n",
    "        \n",
    "        # Load model\n",
    "        fold_dir = OUTPUT_PATH/f\"{args['task_name']}/{fold}/model_out\"\n",
    "        model = BertClassificationPredictor(model_path=fold_dir,  \n",
    "                                        label_path=LABEL_PATH, \n",
    "                                        multi_label=True)\n",
    "        \n",
    "        # Load test data\n",
    "        test_index = np.load(f\"{CROSS_FOLDS}/{fold}/test.npy\")\n",
    "        x_test = x[test_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        loaded_models.append((model, x_test, y_test))\n",
    "print(f\"Finished loading the Bert models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results = metrics_avg(loaded_models, labels_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results[0].to_csv(f'results.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl = round(avg_results[1],4)\n",
    "roc_auc = round(avg_results[2],4)\n",
    "print(f\"hl;{hl}\")\n",
    "print(f\"roc-auc;{roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of fastbert.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
