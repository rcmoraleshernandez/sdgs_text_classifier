{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "JBt_T5zUMG68",
    "outputId": "bd5f1f72-a7d3-451c-b4fe-bd48887ad47c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub==0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow_hub==0.4.0) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow_hub==0.4.0) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow_hub==0.4.0) (1.16.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.4.0->tensorflow_hub==0.4.0) (40.8.0)\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ca/94d32a6516ed197a491d17d46595ce58a83cbb2fca280414e57cd86b84dc/pip-19.2.1-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 22.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting setuptools\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/51/f45cea425fd5cb0b0380f5b0f048ebc1da5b417e48d304838c02d6288a1e/setuptools-41.0.1-py2.py3-none-any.whl (575kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 34.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wheel\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/10/44230dd6bf3563b8f227dbf344c908d412ad2ff48066476672f3a72e174e/wheel-0.33.4-py2.py3-none-any.whl\n",
      "\u001b[31mfairing 0.5.3 has requirement tornado<6.0.0,>=5.1.1, but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mfairing 0.5.3 has requirement urllib3==1.24.2, but you'll have urllib3 1.24.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mdatalab 1.1.4 has requirement six==1.10.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pip, setuptools, wheel\n",
      "  Found existing installation: pip 19.0.3\n",
      "    Uninstalling pip-19.0.3:\n",
      "      Successfully uninstalled pip-19.0.3\n",
      "  Found existing installation: setuptools 40.8.0\n",
      "    Uninstalling setuptools-40.8.0:\n",
      "      Successfully uninstalled setuptools-40.8.0\n",
      "  Found existing installation: wheel 0.33.1\n",
      "    Uninstalling wheel-0.33.1:\n",
      "      Successfully uninstalled wheel-0.33.1\n",
      "Successfully installed pip-19.2.1 setuptools-41.0.1 wheel-0.33.4\n",
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting six>=1.10.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/fd/60ce148d8e4205bdf6da4ffec31348fd33f710c20a882b44319d54fd51ae/protobuf-3.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 59.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/b1/b80dea9e0bbbdd07bf7ba69c6df1aeb3e88b90b85ca326c40be9e29bc37c/grpcio-1.22.0-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 49.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/10/44230dd6bf3563b8f227dbf344c908d412ad2ff48066476672f3a72e174e/wheel-0.33.4-py2.py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/4b/55cfbfd3e5e85016eeef9f21c0ec809d978706a0d60b62cc28aeec8c792f/numpy-1.17.0-cp37-cp37m-manylinux1_x86_64.whl (20.3MB)\n",
      "\u001b[K     |████████████████████████████████| 20.3MB 51.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/ab/d3bed6b92042622d24decc7aadc8877badf18aeca1571045840ad4956d3f/Werkzeug-0.15.5-py2.py3-none-any.whl (328kB)\n",
      "\u001b[K     |████████████████████████████████| 337kB 67.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/51/f45cea425fd5cb0b0380f5b0f048ebc1da5b417e48d304838c02d6288a1e/setuptools-41.0.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 51.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py (from keras-applications>=1.0.6->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/fd/2ca5c4f4ed33ac4178f9c4d551e3946ab480866e3cd67a65a67a4bb35367/h5py-2.9.0-cp37-cp37m-manylinux1_x86_64.whl (2.8MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8MB 71.9MB/s eta 0:00:01\n",
      "\u001b[31mERROR: astroid 2.2.5 requires typed-ast>=1.3.0; implementation_name == \"cpython\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fairing 0.5.3 has requirement tornado<6.0.0,>=5.1.1, but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fairing 0.5.3 has requirement urllib3==1.24.2, but you'll have urllib3 1.24.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datalab 1.1.4 has requirement six==1.10.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: six, google-pasta, tensorflow-estimator, astor, absl-py, werkzeug, setuptools, protobuf, numpy, markdown, grpcio, wheel, tensorboard, h5py, keras-applications, wrapt, keras-preprocessing, gast, termcolor, tensorflow\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.22.0 h5py-2.9.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 numpy-1.17.0 protobuf-3.9.1 setuptools-41.0.1 six-1.12.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 werkzeug-0.15.5 wheel-0.33.4 wrapt-1.11.2\n",
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 56.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 68.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/8e/fd/2ca5c4f4ed33ac4178f9c4d551e3946ab480866e3cd67a65a67a4bb35367/h5py-2.9.0-cp37-cp37m-manylinux1_x86_64.whl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting numpy>=1.9.1 (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/4b/55cfbfd3e5e85016eeef9f21c0ec809d978706a0d60b62cc28aeec8c792f/numpy-1.17.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting six>=1.9.0 (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting scipy>=0.14 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/bd/c0feba81fb60e231cf40fc8a322ed5873c90ef7711795508692b1481a4ae/scipy-1.3.0-cp37-cp37m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2MB 47.7MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp37-cp37m-linux_x86_64.whl size=44104 sha256=c3cb996f3a1849dbcce29cdc8ab26f3aa89e6111b37adbf89a62a65b54931766\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
      "Successfully built pyyaml\n",
      "\u001b[31mERROR: astroid 2.2.5 requires typed-ast>=1.3.0; implementation_name == \"cpython\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fairing 0.5.3 has requirement tornado<6.0.0,>=5.1.1, but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fairing 0.5.3 has requirement urllib3==1.24.2, but you'll have urllib3 1.24.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datalab 1.1.4 has requirement six==1.10.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pyyaml, numpy, six, h5py, keras-applications, keras-preprocessing, scipy, keras\n",
      "Successfully installed h5py-2.9.0 keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0 numpy-1.17.0 pyyaml-5.1.2 scipy-1.3.0 six-1.12.0\n",
      "Requirement already satisfied: iterative-stratification in /opt/anaconda3/lib/python3.7/site-packages (0.1.6)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from iterative-stratification) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.7/site-packages (from iterative-stratification) (0.20.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.7/site-packages (from iterative-stratification) (1.3.0)\n",
      "Requirement already up-to-date: sacremoses in /opt/anaconda3/lib/python3.7/site-packages (0.0.31)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /opt/anaconda3/lib/python3.7/site-packages (from sacremoses) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/anaconda3/lib/python3.7/site-packages (from sacremoses) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: click in /opt/anaconda3/lib/python3.7/site-packages (from sacremoses) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /opt/anaconda3/lib/python3.7/site-packages (from sacremoses) (4.31.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install \"tensorflow_hub==0.4.0\"\n",
    "#!pip install --upgrade pip setuptools wheel\n",
    "#!pip install -I tensorflow\n",
    "#!pip install -I keras\n",
    "#!pip install iterative-stratification\n",
    "#!pip install -U sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "yzkDHu1qhHIa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, hamming_loss, roc_auc_score\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "from keras import backend as K\n",
    "import keras.layers as layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.engine import Layer\n",
    "\n",
    "from sacremoses import MosesTokenizer\n",
    "\n",
    "# Initialize session\n",
    "#sess = tf.Session()\n",
    "#K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pi63MqzME0Ji"
   },
   "outputs": [],
   "source": [
    "TEXT_DATA_DIR = f\"../../datasets/cleanup_labelled.csv\"\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 50\n",
    "N_EPOCHS = 10\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "labels_index = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_nighR5UdrV"
   },
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable=True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
    "                               name=\"{}_module\".format(self.name))\n",
    "        \n",
    "\n",
    "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                      as_dict=True,\n",
    "                      signature='default',\n",
    "                      )['default']\n",
    "        return result\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return K.not_equal(inputs, '--PAD--')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJkKGmTooe0E"
   },
   "outputs": [],
   "source": [
    "# Function to build model\n",
    "def build_model(): \n",
    "    input_text = layers.Input(shape=(1,), dtype=\"string\")\n",
    "    embedding = ElmoEmbeddingLayer()(input_text)\n",
    "    dense = layers.Dense(256, activation='relu')(embedding)\n",
    "    pred = layers.Dense(17, activation='sigmoid')(dense)\n",
    "\n",
    "    model = Model(inputs=[input_text], outputs=pred)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "DYvfb0fCOX_a",
    "outputId": "f8da6174-991b-49eb-a620-a2748267890a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Tokenizing data\n",
      "Fold no. 1\n",
      "Fold no. 2\n",
      "Fold no. 3\n",
      "Fold no. 4\n",
      "Fold no. 5\n",
      "Fold no. 6\n",
      "Fold no. 7\n",
      "Fold no. 8\n",
      "Fold no. 9\n",
      "Fold no. 10\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')\n",
    "mt = MosesTokenizer(lang='en')\n",
    "df = pd.read_csv(TEXT_DATA_DIR)\n",
    "df.labels = df.labels.str.split('|').apply(lambda x: [int(i) for i in x])\n",
    "\n",
    "print('Tokenizing data')\n",
    "data = np.array([mt.tokenize(t, escape=False)[:150] for t in df.text])\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(df.labels)\n",
    "\n",
    "# Cross-validation: split the data into a training set and a test set\n",
    "cross_validation_sets = []\n",
    "count = 0\n",
    "mskf = MultilabelStratifiedKFold(n_splits=10, random_state=0)\n",
    "\n",
    "for train_index, test_index in mskf.split(data, labels):\n",
    "    count += 1\n",
    "    print(f\"Fold no. {count}\")\n",
    "    train_text, test_text = data[train_index], data[test_index]\n",
    "    \n",
    "    # Look into adapting the script to accept list of tokens instead\n",
    "    train_text = [' '.join(t) for t in train_text]\n",
    "    train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "    \n",
    "    test_text = [' '.join(t) for t in test_text]\n",
    "    test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "    \n",
    "    train_label, test_label = labels[train_index], labels[test_index]\n",
    "    cross_validation_sets.append((train_text, train_label, test_text, test_label))\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "zHtvFIu0Zsyx",
    "outputId": "c7fc1dc7-4ed3-42fe-bfa4-a8a911bfc317"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for train_text, train_label, test_text, test_label in cross_validation_sets:\n",
    "    count += 1\n",
    "    print(f\"Fold {count}\")\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit(train_text, \n",
    "          train_label,\n",
    "          epochs=N_EPOCHS,\n",
    "          batch_size=32)\n",
    "    model.save(f\"elmo_{N_EPOCHS}_epochs_crossvalidated_fold_{count}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ki-1denqGAUj"
   },
   "outputs": [],
   "source": [
    "def metrics_avg(models_testx_testy, labels_, thres=0.3):\n",
    "    def calc(model, test_x, test_y):\n",
    "    predictions = model.predict(test_x)>thres\n",
    "    metrics = classification_report(test_y, predictions, target_names=labels_, output_dict=True)\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics)\n",
    "    h = hamming_loss(test_y, predictions)\n",
    "    roc = roc_auc_score(test_y, predictions, average='micro')\n",
    "        return metrics_df, h, roc\n",
    "\n",
    "    model_1, test_x_1, test_y_1 = models_testx_testy[0]\n",
    "    metrics_agg, ham, roc = calc(model_1, test_x_1, test_y_1)\n",
    "    n = len(models_testx_testy)\n",
    "\n",
    "    for model, test_x, test_y_1 in models_testx_testy[1:]:\n",
    "        metrics, h, r = calc(model, test_x, test_y_1)\n",
    "        metrics_agg += metrics\n",
    "        ham += h\n",
    "        roc += r\n",
    "\n",
    "    return metrics_agg/n, ham/n, roc/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "colab_type": "code",
    "id": "yT92tW4qGCsD",
    "outputId": "66aba9a4-5b73-471b-b220-76c75aa49e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "elmo_embedding_layer_19 (Elm (None, 1024)              4         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 17)                4369      \n",
      "=================================================================\n",
      "Total params: 266,773\n",
      "Trainable params: 266,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "labels = [str(i) for i in range(1,18)]\n",
    "model = None\n",
    "model = build_model()\n",
    "model.load_weights('elmo_15epochs_crossvalidated_fold_1.h5')\n",
    "#averaged_results = metrics_avg([(model, test_text, test_label)], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSKFkaq0HeCD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_text, train_label, test_text, test_label =  cross_validation_sets[0]\n",
    "avg_results = metrics_avg([(model, test_text, test_label)], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789815538905387"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4711/4711 [==============================] - 948s 201ms/step - loss: 0.0859 - acc: 0.9699\n",
      "Epoch 2/5\n",
      "4711/4711 [==============================] - 936s 199ms/step - loss: 0.0771 - acc: 0.9727\n",
      "Epoch 3/5\n",
      "4711/4711 [==============================] - 930s 197ms/step - loss: 0.0710 - acc: 0.9753\n",
      "Epoch 4/5\n",
      "4711/4711 [==============================] - 934s 198ms/step - loss: 0.0659 - acc: 0.9766\n",
      "Epoch 5/5\n",
      "4711/4711 [==============================] - 936s 199ms/step - loss: 0.0582 - acc: 0.9806\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_text, \n",
    "          train_label,\n",
    "          epochs=5,\n",
    "          batch_size=32)\n",
    "model.save(f\"elmo_20epochs_crossvalidated_fold_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "avg_results = metrics_avg([(model, test_text, test_label)], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7735558335056892"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_results[2]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "word-embeddings-elmo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
