{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traditional_ml_cross_entropy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vondersam/sdgs_text_classifier/blob/master/experiments/traditional_ml_cross_entropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB6aDzb72Lz3",
        "colab_type": "code",
        "outputId": "d940ed15-5b7d-4dd3-e58a-63956f677138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "#!pip install iterative-stratification\n",
        "#!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting iterative-stratification\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/79/9ba64c8c07b07b8b45d80725b2ebd7b7884701c1da34f70d4749f7b45f9a/iterative_stratification-0.1.6-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (0.21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.16.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->iterative-stratification) (0.13.2)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.6\n",
            "Collecting en_core_web_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz#egg=en_core_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
            "\u001b[K     |████████████████████████████████| 826.9MB 1.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255076 sha256=271eedc8c6419b2fa8c81dab6582a6fef5da79e006a303b6c52371cde8ad95dd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l7ufrop5/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6p8vLIwha9i",
        "colab_type": "code",
        "outputId": "898398cb-9a15-4674-b0ea-ae1590399991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import string\n",
        "\n",
        "### SKLEARN ###\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score, hamming_loss, accuracy_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "### NLTK ###\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk import sent_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "### SPACY ###\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_lg', disable=['ner', 'parser'])\n",
        "spacy_stop_words = spacy.lang.en.stop_words.STOP_WORDS"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbXFaXGGhr21",
        "colab_type": "code",
        "outputId": "5106281b-fd11-4547-f17c-954f12d82fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "base_dir = \"gdrive/My Drive/fastai-v3/sdgs/dataset/\"\n",
        "labelled_dataset = base_dir + \"cleanup_labelled.csv\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEVes-M5h8r8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(labelled_dataset)\n",
        "df.labels = df.labels.str.split('|').apply(lambda x: [int(i) for i in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwDFmhd99uVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SpacyPreprocessor(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.stopwords  = spacy_stop_words\n",
        "        self.punct      = set(string.punctuation)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def inverse_transform(self, X):\n",
        "        return [\" \".join(doc) for doc in X]\n",
        "\n",
        "    def transform(self, X):\n",
        "        return [\n",
        "            list(self.tokenize(doc)) for doc in X\n",
        "        ]\n",
        "\n",
        "    def tokenize(self, document):\n",
        "        for token in nlp(document):\n",
        "\n",
        "            # Disregard stopwords\n",
        "            if token in self.stopwords:\n",
        "                continue\n",
        "\n",
        "            # Disregard punctuation\n",
        "            if all(char in self.punct for char in token.text):\n",
        "                continue\n",
        "\n",
        "            # yield lemmatized tokens\n",
        "            yield token.lemma_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoc981iI6psQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, stopwords=None, punct=None,\n",
        "                 lower=True, strip=True):\n",
        "        self.stopwords  = set(sw.words('english'))\n",
        "        self.punct      = set(string.punctuation)\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def inverse_transform(self, X):\n",
        "        return [\" \".join(doc) for doc in X]\n",
        "\n",
        "    def transform(self, X):\n",
        "        return [\n",
        "            list(self.tokenize(doc)) for doc in X\n",
        "        ]\n",
        "\n",
        "    def tokenize(self, document):\n",
        "        for token, tag in pos_tag(word_tokenize(document)):\n",
        "            token = token.lower()\n",
        "            token = token.strip()\n",
        "            token = token.strip('_')\n",
        "            token = token.strip('*')\n",
        "\n",
        "            # Disregard stopwords\n",
        "            if token in self.stopwords:\n",
        "                continue\n",
        "\n",
        "            # Disregard punctuation\n",
        "            if all(char in self.punct for char in token):\n",
        "                continue\n",
        "\n",
        "            # yield lemmatized tokens\n",
        "            lemma = self.lemmatize(token, tag)\n",
        "            yield lemma\n",
        "\n",
        "    def lemmatize(self, token, tag):\n",
        "        tag = {\n",
        "            'N': wn.NOUN,\n",
        "            'V': wn.VERB,\n",
        "            'R': wn.ADV,\n",
        "            'J': wn.ADJ\n",
        "        }.get(tag[0], wn.NOUN)\n",
        "        return self.lemmatizer.lemmatize(token, tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGWKkATC9Wav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity(arg):\n",
        "    \"\"\"\n",
        "    Simple identity function works as a passthrough.\n",
        "    \"\"\"\n",
        "    return arg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDT5rTaHV9jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_classifier(train_x, train_y, type_, preprocessor=NLTKPreprocessor()):\n",
        "  if type_ == 'svm':\n",
        "    clf = OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight='balanced', dual=True,\n",
        "                                        fit_intercept=True, intercept_scaling=1,\n",
        "                                        loss='squared_hinge', max_iter=1000,\n",
        "                                        multi_class='ovr', penalty='l2',\n",
        "                                        random_state=None, tol=0.0001,\n",
        "                                        verbose=0))\n",
        "    \n",
        "    word_vectorizer = TfidfVectorizer(binary=False, decode_error='strict',\n",
        "                encoding='utf-8', dtype=np.float64,\n",
        "                input='content', lowercase=False, max_df=0.25, max_features=None,\n",
        "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
        "                smooth_idf=True,\n",
        "                stop_words=None,\n",
        "                strip_accents=None, sublinear_tf=False,\n",
        "                tokenizer=identity, use_idf=True,\n",
        "                vocabulary=None)\n",
        "\n",
        "  elif type_ == 'nb':\n",
        "    clf = OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None,\n",
        "                                            fit_prior=True))\n",
        "                          \n",
        "    word_vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
        "                dtype=np.float64, encoding='utf-8',\n",
        "                input='content', lowercase=False, max_df=0.25, max_features=None,\n",
        "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
        "                smooth_idf=True,\n",
        "                stop_words=None,\n",
        "                strip_accents=None, sublinear_tf=False,\n",
        "                tokenizer=identity, use_idf=True,\n",
        "                vocabulary=None)\n",
        "    \n",
        "  elif type_ == 'lg':\n",
        "    clf = OneVsRestClassifier(estimator=LogisticRegression(C=1, class_weight='balanced',\n",
        "                                                 dual=False, fit_intercept=True,\n",
        "                                                 intercept_scaling=1,\n",
        "                                                 l1_ratio=None, max_iter=2000,\n",
        "                                                 multi_class='warn',\n",
        "                                                 n_jobs=None, penalty='l2',\n",
        "                                                 random_state=None,\n",
        "                                                 solver='sag', tol=0.0001,\n",
        "                                                 verbose=0, warm_start=False),\n",
        "                                                 n_jobs=None)\n",
        "    \n",
        "    word_vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
        "                dtype=np.float64, encoding='utf-8',\n",
        "                input='content', lowercase=False, max_df=0.25, max_features=None,\n",
        "                min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
        "                smooth_idf=True,\n",
        "                stop_words=None,\n",
        "                strip_accents=None, sublinear_tf=False,\n",
        "                tokenizer=identity, use_idf=True,\n",
        "                vocabulary=None)\n",
        "    \n",
        "  pipe = Pipeline([('preprocessor', preprocessor), ('tfidf', word_vectorizer), ('multilabel', clf)])\n",
        "  pipe.fit(train_x, train_y)\n",
        "  return pipe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwmb4EOCI-Gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics_avg(models_testx_testy, labels_):\n",
        "  def calc(model, test_x, test_y):\n",
        "    predictions = model.predict(test_x)\n",
        "    metrics = classification_report(test_y, predictions, target_names=labels_, output_dict=True)\n",
        "    metrics_df = pd.DataFrame.from_dict(metrics)\n",
        "    h = hamming_loss(test_y, predictions)\n",
        "    roc = roc_auc_score(test_y, predictions, average='micro')\n",
        "    return metrics_df, h, roc\n",
        "    \n",
        "  model_1, test_x_1, test_y_1 = models_testx_testy[0]\n",
        "  metrics_agg, ham, roc = calc(model_1, test_x_1, test_y_1)\n",
        "  n = len(models_testx_testy)\n",
        "  \n",
        "  for model, test_x, test_y_1 in models_testx_testy[1:]:\n",
        "    metrics, h, r = calc(model, test_x, test_y_1)\n",
        "    metrics_agg += metrics\n",
        "    ham += h\n",
        "    roc += r\n",
        "  \n",
        "  return metrics_agg/n, ham/n, roc/n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "59f555ba-82bf-45cc-fe77-bef669241fbe",
        "id": "EIY5pZzCMNLt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "mskf = MultilabelStratifiedKFold(n_splits=10, random_state=0)\n",
        "mlb = MultiLabelBinarizer()\n",
        "results = []\n",
        "x = df[['text']].values # text\n",
        "y = mlb.fit_transform(df.labels) # labels\n",
        "count = 0\n",
        "labels = [str(i) for i in range(1,18)]\n",
        "\n",
        "for train_index, test_index in mskf.split(x, y):\n",
        "  count += 1\n",
        "  print(f\"Fold no. {count}\")\n",
        "\n",
        "  x_train, x_test = [t[0] for t in x[train_index].tolist()], [t[0] for t in x[test_index].tolist()]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  model =  run_classifier(x_train, y_train, 'lg')\n",
        "  results.append((model, x_test, y_test))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold no. 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold no. 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold no. 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold no. 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold no. 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold no. 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold no. 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold no. 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold no. 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold no. 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_oyy-rgTn_o",
        "colab_type": "code",
        "outputId": "b0339b87-8c04-4d32-e5fb-fcc12e47406c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "avg_results = metrics_avg(results, labels)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVIczVT3lbgN",
        "colab_type": "code",
        "outputId": "1eed6db2-9f55-4ad2-8529-fc1ed4afd806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "avg_results[2]"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8823201752913954"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mej_hEuZG8Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}