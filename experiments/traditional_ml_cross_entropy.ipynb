{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traditional_ml_cross_entropy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vondersam/sdgs_text_classifier/blob/master/experiments/traditional_ml_cross_entropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB6aDzb72Lz3",
        "colab_type": "code",
        "outputId": "200119d0-1782-4f49-8ab8-70630480c5c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install iterative-stratification\n",
        "#!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: iterative-stratification in /usr/local/lib/python3.6/dist-packages (0.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (0.21.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->iterative-stratification) (0.13.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6p8vLIwha9i",
        "colab_type": "code",
        "outputId": "1d246849-e140-4e79-8dd2-f2051973e753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import string\n",
        "\n",
        "### SKLEARN ###\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, hamming_loss, accuracy_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.decomposition import PCA, NMF\n",
        "\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "### NLTK ###\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk import sent_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "### SPACY ###\n",
        "#import spacy\n",
        "#spacy_stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "#nlp = spacy.load('en_core_web_lg', disable=['ner', 'parser'])\n",
        "from joblib import dump, load"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbXFaXGGhr21",
        "colab_type": "code",
        "outputId": "4996c4d7-7f5e-4154-84b0-fa1d6910c243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "base_dir = \"gdrive/My Drive/fastai-v3/sdgs/dataset/\"\n",
        "labelled_dataset = base_dir + \"cleanup_labelled.csv\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEVes-M5h8r8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(labelled_dataset)\n",
        "df.labels = df.labels.str.split('|').apply(lambda x: [int(i) for i in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq-Npyjn70jj",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwDFmhd99uVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SpacyPreprocessor(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.stopwords  = spacy_stop_words\n",
        "        self.punct      = set(string.punctuation)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def inverse_transform(self, X):\n",
        "        return [\" \".join(doc) for doc in X]\n",
        "\n",
        "    def transform(self, X):\n",
        "        return [\n",
        "            list(self.tokenize(doc)) for doc in X\n",
        "        ]\n",
        "\n",
        "    def tokenize(self, document):\n",
        "        for token in nlp(document):\n",
        "\n",
        "            # Disregard stopwords\n",
        "            if token in self.stopwords:\n",
        "                continue\n",
        "\n",
        "            # Disregard punctuation\n",
        "            if all(char in self.punct for char in token.text):\n",
        "                continue\n",
        "\n",
        "            # yield lemmatized tokens\n",
        "            yield token.lemma_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoc981iI6psQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, stopwords=None, punct=None,\n",
        "                 lower=True, strip=True):\n",
        "        self.stopwords  = set(sw.words('english'))\n",
        "        self.punct      = set(string.punctuation)\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def inverse_transform(self, X):\n",
        "        return [\" \".join(doc) for doc in X]\n",
        "\n",
        "    def transform(self, X):\n",
        "        return [\n",
        "            list(self.tokenize(doc)) for doc in X\n",
        "        ]\n",
        "\n",
        "    def tokenize(self, document):\n",
        "        for token, tag in pos_tag(word_tokenize(document)):\n",
        "            token = token.lower()\n",
        "            token = token.strip()\n",
        "            token = token.strip('_')\n",
        "            token = token.strip('*')\n",
        "\n",
        "            # Disregard stopwords\n",
        "            if token in self.stopwords:\n",
        "                continue\n",
        "\n",
        "            # Disregard punctuation\n",
        "            if all(char in self.punct for char in token):\n",
        "                continue\n",
        "\n",
        "            # yield lemmatized tokens\n",
        "            lemma = self.lemmatize(token, tag)\n",
        "            yield lemma\n",
        "\n",
        "    def lemmatize(self, token, tag):\n",
        "        tag = {\n",
        "            'N': wn.NOUN,\n",
        "            'V': wn.VERB,\n",
        "            'R': wn.ADV,\n",
        "            'J': wn.ADJ\n",
        "        }.get(tag[0], wn.NOUN)\n",
        "        return self.lemmatizer.lemmatize(token, tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGWKkATC9Wav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity(arg):\n",
        "    \"\"\"\n",
        "    Simple identity function works as a passthrough.\n",
        "    \"\"\"\n",
        "    return arg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAWjeu2n7rNU",
        "colab_type": "text"
      },
      "source": [
        "# Pipeline with preprocessor, vectorizer and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDT5rTaHV9jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_classifier(train_x, train_y, type_, preprocessor=NLTKPreprocessor()):\n",
        "  if type_ == 'svm':\n",
        "    clf = OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight='balanced', dual=True,\n",
        "                                        fit_intercept=True, intercept_scaling=1,\n",
        "                                        loss='squared_hinge', max_iter=1000,\n",
        "                                        multi_class='ovr', penalty='l2',\n",
        "                                        random_state=None, tol=0.0001,\n",
        "                                        verbose=0))\n",
        "    \n",
        "    word_vectorizer = TfidfVectorizer(binary=False, decode_error='strict',\n",
        "                encoding='utf-8', dtype=np.float64,\n",
        "                input='content', lowercase=False, max_df=0.25, max_features=None,\n",
        "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
        "                smooth_idf=True,\n",
        "                stop_words=None,\n",
        "                strip_accents=None, sublinear_tf=False,\n",
        "                tokenizer=identity, use_idf=True,\n",
        "                vocabulary=None)\n",
        "    \n",
        "    #feature_selector = SelectKBest(chi2, k=10000)\n",
        "\n",
        "  elif type_ == 'nb':\n",
        "    clf = OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None,\n",
        "                                            fit_prior=True))\n",
        "                          \n",
        "    word_vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
        "                dtype=np.float64, encoding='utf-8',\n",
        "                input='content', lowercase=False, max_df=0.25, max_features=None,\n",
        "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
        "                smooth_idf=True,\n",
        "                stop_words=None,\n",
        "                strip_accents=None, sublinear_tf=False,\n",
        "                tokenizer=identity, use_idf=True,\n",
        "                vocabulary=None)\n",
        "  elif type_ == 'lg':\n",
        "    clf = OneVsRestClassifier(estimator=LogisticRegression(C=1, class_weight='balanced',\n",
        "                                                 dual=False, fit_intercept=True,\n",
        "                                                 intercept_scaling=1,\n",
        "                                                 l1_ratio=None, max_iter=4000,\n",
        "                                                 multi_class='ovr',\n",
        "                                                 n_jobs=None, penalty='l2',\n",
        "                                                 random_state=None,\n",
        "                                                 solver='sag', tol=0.0001,\n",
        "                                                 verbose=0, warm_start=False),\n",
        "                                                 n_jobs=None)\n",
        "    \n",
        "    word_vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
        "                dtype=np.float64, encoding='utf-8',\n",
        "                input='content', lowercase=False, max_df=0.25, max_features=None,\n",
        "                min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
        "                smooth_idf=True,\n",
        "                stop_words=None,\n",
        "                strip_accents=None, sublinear_tf=False,\n",
        "                tokenizer=identity, use_idf=True,\n",
        "                vocabulary=None)\n",
        "  elif type_ == 'knn':\n",
        "        clf = KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
        "                     weights='distance')\n",
        "        word_vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
        "                dtype=np.float64, encoding='utf-8',\n",
        "                input='content', lowercase=False, max_df=0.5, max_features=None,\n",
        "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
        "                stop_words=None,\n",
        "                strip_accents=None, sublinear_tf=False,\n",
        "                tokenizer=identity, use_idf=True,\n",
        "                vocabulary=None)\n",
        "    \n",
        "  pipe = Pipeline([('preprocessor', preprocessor), ('tfidf', word_vectorizer), ('multilabel', clf)])\n",
        "  pipe.fit(train_x, train_y)\n",
        "  return pipe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5MfhEZJ7lbu",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwmb4EOCI-Gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics_avg(models_testx_testy, labels_):\n",
        "  def calc(model, test_x, test_y):\n",
        "    predictions = model.predict(test_x)\n",
        "    metrics = classification_report(test_y, predictions, target_names=labels_, output_dict=True)\n",
        "    metrics_df = pd.DataFrame.from_dict(metrics)\n",
        "    h = hamming_loss(test_y, predictions)\n",
        "    roc = roc_auc_score(test_y, predictions, average='micro')\n",
        "    return metrics_df, h, roc\n",
        "    \n",
        "  model_1, test_x_1, test_y_1 = models_testx_testy[0]\n",
        "  metrics_agg, ham, roc = calc(model_1, test_x_1, test_y_1)\n",
        "  n = len(models_testx_testy)\n",
        "  \n",
        "  for model, test_x, test_y_1 in models_testx_testy[1:]:\n",
        "    metrics, h, r = calc(model, test_x, test_y_1)\n",
        "    metrics_agg += metrics\n",
        "    ham += h\n",
        "    roc += r\n",
        "  \n",
        "  return metrics_agg/n, ham/n, roc/n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EIY5pZzCMNLt",
        "colab": {}
      },
      "source": [
        "mskf = MultilabelStratifiedKFold(n_splits=10, random_state=0)\n",
        "mlb = MultiLabelBinarizer()\n",
        "results = []\n",
        "x = df[['text']].values # text\n",
        "y = mlb.fit_transform(df.labels) # labels\n",
        "count = 0\n",
        "labels = [str(i) for i in range(1,18)]\n",
        "\n",
        "for train_index, test_index in mskf.split(x, y):\n",
        "  count += 1\n",
        "  print(f\"Fold no. {count}\")\n",
        "\n",
        "  x_train, x_test = [t[0] for t in x[train_index].tolist()], [t[0] for t in x[test_index].tolist()]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  model =  run_classifier(x_train, y_train, 'lg')\n",
        "  results.append((model, x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_oyy-rgTn_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_results = metrics_avg(results, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVIczVT3lbgN",
        "colab_type": "code",
        "outputId": "a27bca04-3ef2-4a0f-f66a-8ee1653994f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "avg_results[2]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.88211197331132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsDQdJ7G7Z_X",
        "colab_type": "text"
      },
      "source": [
        "# Save models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDX_-E4fN97G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f661d48-26f1-4beb-9831-90e9491a8cc9"
      },
      "source": [
        "count = 0\n",
        "save_dir = \"gdrive/My Drive/fastai-v3/sdgs/logistic_regression/\"\n",
        "for each_model, each_test_x, each_test_y in results:\n",
        "    count += 1\n",
        "    dump(each_model, save_dir + f\"lg_fold{count}.joblib\")\n",
        "print(\"All models saved.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All models saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmZ5YDm07egJ",
        "colab_type": "text"
      },
      "source": [
        "# Load models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywBE6Hdu4bQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "for i in range(1,11):\n",
        "    model = load(save_dir + f\"lg_fold{i}.joblib\")\n",
        "    results.append(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpjl5hT74xCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "136582c9-6749-4edc-cd5c-9e8f1d7a5061"
      },
      "source": [
        "results"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Pipeline(memory=None,\n",
              "          steps=[('preprocessor',\n",
              "                  NLTKPreprocessor(lower=None,\n",
              "                                   punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
              "                                          ')', '*', '+', ',', '-', '.', '/', ':',\n",
              "                                          ';', '<', '=', '>', '?', '@', '[',\n",
              "                                          '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
              "                                   stopwords={'a', 'about', 'above', 'after',\n",
              "                                              'again', 'against', 'ain', 'all',\n",
              "                                              'am', 'an', 'and', 'any', 'are',\n",
              "                                              'aren', \"aren't\", 'as', 'at', 'be',\n",
              "                                              'because', 'been',...\n",
              "                                  tokenizer=<function identity at 0x7ff37b9bcb70>,\n",
              "                                  use_idf=True, vocabulary=None)),\n",
              "                 ('multilabel',\n",
              "                  OneVsRestClassifier(estimator=LogisticRegression(C=1,\n",
              "                                                                   class_weight='balanced',\n",
              "                                                                   dual=False,\n",
              "                                                                   fit_intercept=True,\n",
              "                                                                   intercept_scaling=1,\n",
              "                                                                   l1_ratio=None,\n",
              "                                                                   max_iter=4000,\n",
              "                                                                   multi_class='ovr',\n",
              "                                                                   n_jobs=None,\n",
              "                                                                   penalty='l2',\n",
              "                                                                   random_state=None,\n",
              "                                                                   solver='sag',\n",
              "                                                                   tol=0.0001,\n",
              "                                                                   verbose=0,\n",
              "                                                                   warm_start=False),\n",
              "                                      n_jobs=None))],\n",
              "          verbose=False), Pipeline(memory=None,\n",
              "          steps=[('preprocessor',\n",
              "                  NLTKPreprocessor(lower=None,\n",
              "                                   punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
              "                                          ')', '*', '+', ',', '-', '.', '/', ':',\n",
              "                                          ';', '<', '=', '>', '?', '@', '[',\n",
              "                                          '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
              "                                   stopwords={'a', 'about', 'above', 'after',\n",
              "                                              'again', 'against', 'ain', 'all',\n",
              "                                              'am', 'an', 'and', 'any', 'are',\n",
              "                                              'aren', \"aren't\", 'as', 'at', 'be',\n",
              "                                              'because', 'been',...\n",
              "                                  tokenizer=<function identity at 0x7ff37b9bcb70>,\n",
              "                                  use_idf=True, vocabulary=None)),\n",
              "                 ('multilabel',\n",
              "                  OneVsRestClassifier(estimator=LogisticRegression(C=1,\n",
              "                                                                   class_weight='balanced',\n",
              "                                                                   dual=False,\n",
              "                                                                   fit_intercept=True,\n",
              "                                                                   intercept_scaling=1,\n",
              "                                                                   l1_ratio=None,\n",
              "                                                                   max_iter=4000,\n",
              "                                                                   multi_class='ovr',\n",
              "                                                                   n_jobs=None,\n",
              "                                                                   penalty='l2',\n",
              "                                                                   random_state=None,\n",
              "                                                                   solver='sag',\n",
              "                                                                   tol=0.0001,\n",
              "                                                                   verbose=0,\n",
              "                                                                   warm_start=False),\n",
              "                                      n_jobs=None))],\n",
              "          verbose=False), Pipeline(memory=None,\n",
              "          steps=[('preprocessor',\n",
              "                  NLTKPreprocessor(lower=None,\n",
              "                                   punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
              "                                          ')', '*', '+', ',', '-', '.', '/', ':',\n",
              "                                          ';', '<', '=', '>', '?', '@', '[',\n",
              "                                          '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
              "                                   stopwords={'a', 'about', 'above', 'after',\n",
              "                                              'again', 'against', 'ain', 'all',\n",
              "                                              'am', 'an', 'and', 'any', 'are',\n",
              "                                              'aren', \"aren't\", 'as', 'at', 'be',\n",
              "                                              'because', 'been',...\n",
              "                                  tokenizer=<function identity at 0x7ff37b9bcb70>,\n",
              "                                  use_idf=True, vocabulary=None)),\n",
              "                 ('multilabel',\n",
              "                  OneVsRestClassifier(estimator=LogisticRegression(C=1,\n",
              "                                                                   class_weight='balanced',\n",
              "                                                                   dual=False,\n",
              "                                                                   fit_intercept=True,\n",
              "                                                                   intercept_scaling=1,\n",
              "                                                                   l1_ratio=None,\n",
              "                                                                   max_iter=4000,\n",
              "                                                                   multi_class='ovr',\n",
              "                                                                   n_jobs=None,\n",
              "                                                                   penalty='l2',\n",
              "                                                                   random_state=None,\n",
              "                                                                   solver='sag',\n",
              "                                                                   tol=0.0001,\n",
              "                                                                   verbose=0,\n",
              "                                                                   warm_start=False),\n",
              "                                      n_jobs=None))],\n",
              "          verbose=False), Pipeline(memory=None,\n",
              "          steps=[('preprocessor',\n",
              "                  NLTKPreprocessor(lower=None,\n",
              "                                   punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
              "                                          ')', '*', '+', ',', '-', '.', '/', ':',\n",
              "                                          ';', '<', '=', '>', '?', '@', '[',\n",
              "                                          '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
              "                                   stopwords={'a', 'about', 'above', 'after',\n",
              "                                              'again', 'against', 'ain', 'all',\n",
              "                                              'am', 'an', 'and', 'any', 'are',\n",
              "                                              'aren', \"aren't\", 'as', 'at', 'be',\n",
              "                                              'because', 'been',...\n",
              "                                  tokenizer=<function identity at 0x7ff37b9bcb70>,\n",
              "                                  use_idf=True, vocabulary=None)),\n",
              "                 ('multilabel',\n",
              "                  OneVsRestClassifier(estimator=LogisticRegression(C=1,\n",
              "                                                                   class_weight='balanced',\n",
              "                                                                   dual=False,\n",
              "                                                                   fit_intercept=True,\n",
              "                                                                   intercept_scaling=1,\n",
              "                                                                   l1_ratio=None,\n",
              "                                                                   max_iter=4000,\n",
              "                                                                   multi_class='ovr',\n",
              "                                                                   n_jobs=None,\n",
              "                                                                   penalty='l2',\n",
              "                                                                   random_state=None,\n",
              "                                                                   solver='sag',\n",
              "                                                                   tol=0.0001,\n",
              "                                                                   verbose=0,\n",
              "                                                                   warm_start=False),\n",
              "                                      n_jobs=None))],\n",
              "          verbose=False), Pipeline(memory=None,\n",
              "          steps=[('preprocessor',\n",
              "                  NLTKPreprocessor(lower=None,\n",
              "                                   punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
              "                                          ')', '*', '+', ',', '-', '.', '/', ':',\n",
              "                                          ';', '<', '=', '>', '?', '@', '[',\n",
              "                                          '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
              "                                   stopwords={'a', 'about', 'above', 'after',\n",
              "                                              'again', 'against', 'ain', 'all',\n",
              "                                              'am', 'an', 'and', 'any', 'are',\n",
              "                                              'aren', \"aren't\", 'as', 'at', 'be',\n",
              "                                              'because', 'been',...\n",
              "                                  tokenizer=<function identity at 0x7ff37b9bcb70>,\n",
              "                                  use_idf=True, vocabulary=None)),\n",
              "                 ('multilabel',\n",
              "                  OneVsRestClassifier(estimator=LogisticRegression(C=1,\n",
              "                                                                   class_weight='balanced',\n",
              "                                                                   dual=False,\n",
              "                                                                   fit_intercept=True,\n",
              "                                                                   intercept_scaling=1,\n",
              "                                                                   l1_ratio=None,\n",
              "                                                                   max_iter=4000,\n",
              "                                                                   multi_class='ovr',\n",
              "                                                                   n_jobs=None,\n",
              "                                                                   penalty='l2',\n",
              "                                                                   random_state=None,\n",
              "                                                                   solver='sag',\n",
              "                                                                   tol=0.0001,\n",
              "                                                                   verbose=0,\n",
              "                                                                   warm_start=False),\n",
              "                                      n_jobs=None))],\n",
              "          verbose=False), Pipeline(memory=None,\n",
              "          steps=[('preprocessor',\n",
              "                  NLTKPreprocessor(lower=None,\n",
              "                                   punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
              "                                          ')', '*', '+', ',', '-', '.', '/', ':',\n",
              "                                          ';', '<', '=', '>', '?', '@', '[',\n",
              "                                          '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
              "                                   stopwords={'a', 'about', 'above', 'after',\n",
              "                                              'again', 'against', 'ain', 'all',\n",
              "                                              'am', 'an', 'and', 'any', 'are',\n",
              "                                              'aren', \"aren't\", 'as', 'at', 'be',\n",
              "                                              'because', 'been',...\n",
              "                                  tokenizer=<function identity at 0x7ff37b9bcb70>,\n",
              "                                  use_idf=True, vocabulary=None)),\n",
              "                 ('multilabel',\n",
              "                  OneVsRestClassifier(estimator=LogisticRegression(C=1,\n",
              "                                                                   class_weight='balanced',\n",
              "                                                                   dual=False,\n",
              "                                                                   fit_intercept=True,\n",
              "                                                                   intercept_scaling=1,\n",
              "                                                                   l1_ratio=None,\n",
              "                                                                   max_iter=4000,\n",
              "                                                                   multi_class='ovr',\n",
              "                                                                   n_jobs=None,\n",
              "                                                                   penalty='l2',\n",
              "                                                                   random_state=None,\n",
              "                                                                   solver='sag',\n",
              "                                                                   tol=0.0001,\n",
              "                                                                   verbose=0,\n",
              "                                                                   warm_start=False),\n",
              "                                      n_jobs=None))],\n",
              "          verbose=False), Pipeline(memory=None,\n",
              "          steps=[('preprocessor',\n",
              "                  NLTKPreprocessor(lower=None,\n",
              "                                   punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
              "                                          ')', '*', '+', ',', '-', '.', '/', ':',\n",
              "                                          ';', '<', '=', '>', '?', '@', '[',\n",
              "                                          '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
              "                                   stopwords={'a', 'about', 'above', 'after',\n",
              "                                              'again', 'against', 'ain', 'all',\n",
              "                                              'am', 'an', 'and', 'any', 'are',\n",
              "                                              'aren', \"aren't\", 'as', 'at', 'be',\n",
              "                                              'because', 'been',...\n",
              "                                  tokenizer=<function identity at 0x7ff37b9bcb70>,\n",
              "                                  use_idf=True, vocabulary=None)),\n",
              "                 ('multilabel',\n",
              "                  OneVsRestClassifier(estimator=LogisticRegression(C=1,\n",
              "                                                                   class_weight='balanced',\n",
              "                                                                   dual=False,\n",
              "                                                                   fit_intercept=True,\n",
              "                                                                   intercept_scaling=1,\n",
              "                                                                   l1_ratio=None,\n",
              "                                                                   max_iter=4000,\n",
              "                                                                   multi_class='ovr',\n",
              "                                                                   n_jobs=None,\n",
              "                                                                   penalty='l2',\n",
              "                                                                   random_state=None,\n",
              "                                                                   solver='sag',\n",
              "                                                                   tol=0.0001,\n",
              "                                                                   verbose=0,\n",
              "                                                                   warm_start=False),\n",
              "                                      n_jobs=None))],\n",
              "          verbose=False), Pipeline(memory=None,\n",
              "          steps=[('preprocessor',\n",
              "                  NLTKPreprocessor(lower=None,\n",
              "                                   punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
              "                                          ')', '*', '+', ',', '-', '.', '/', ':',\n",
              "                                          ';', '<', '=', '>', '?', '@', '[',\n",
              "                                          '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
              "                                   stopwords={'a', 'about', 'above', 'after',\n",
              "                                              'again', 'against', 'ain', 'all',\n",
              "                                              'am', 'an', 'and', 'any', 'are',\n",
              "                                              'aren', \"aren't\", 'as', 'at', 'be',\n",
              "                                              'because', 'been',...\n",
              "                                  tokenizer=<function identity at 0x7ff37b9bcb70>,\n",
              "                                  use_idf=True, vocabulary=None)),\n",
              "                 ('multilabel',\n",
              "                  OneVsRestClassifier(estimator=LogisticRegression(C=1,\n",
              "                                                                   class_weight='balanced',\n",
              "                                                                   dual=False,\n",
              "                                                                   fit_intercept=True,\n",
              "                                                                   intercept_scaling=1,\n",
              "                                                                   l1_ratio=None,\n",
              "                                                                   max_iter=4000,\n",
              "                                                                   multi_class='ovr',\n",
              "                                                                   n_jobs=None,\n",
              "                                                                   penalty='l2',\n",
              "                                                                   random_state=None,\n",
              "                                                                   solver='sag',\n",
              "                                                                   tol=0.0001,\n",
              "                                                                   verbose=0,\n",
              "                                                                   warm_start=False),\n",
              "                                      n_jobs=None))],\n",
              "          verbose=False), Pipeline(memory=None,\n",
              "          steps=[('preprocessor',\n",
              "                  NLTKPreprocessor(lower=None,\n",
              "                                   punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
              "                                          ')', '*', '+', ',', '-', '.', '/', ':',\n",
              "                                          ';', '<', '=', '>', '?', '@', '[',\n",
              "                                          '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
              "                                   stopwords={'a', 'about', 'above', 'after',\n",
              "                                              'again', 'against', 'ain', 'all',\n",
              "                                              'am', 'an', 'and', 'any', 'are',\n",
              "                                              'aren', \"aren't\", 'as', 'at', 'be',\n",
              "                                              'because', 'been',...\n",
              "                                  tokenizer=<function identity at 0x7ff37b9bcb70>,\n",
              "                                  use_idf=True, vocabulary=None)),\n",
              "                 ('multilabel',\n",
              "                  OneVsRestClassifier(estimator=LogisticRegression(C=1,\n",
              "                                                                   class_weight='balanced',\n",
              "                                                                   dual=False,\n",
              "                                                                   fit_intercept=True,\n",
              "                                                                   intercept_scaling=1,\n",
              "                                                                   l1_ratio=None,\n",
              "                                                                   max_iter=4000,\n",
              "                                                                   multi_class='ovr',\n",
              "                                                                   n_jobs=None,\n",
              "                                                                   penalty='l2',\n",
              "                                                                   random_state=None,\n",
              "                                                                   solver='sag',\n",
              "                                                                   tol=0.0001,\n",
              "                                                                   verbose=0,\n",
              "                                                                   warm_start=False),\n",
              "                                      n_jobs=None))],\n",
              "          verbose=False), Pipeline(memory=None,\n",
              "          steps=[('preprocessor',\n",
              "                  NLTKPreprocessor(lower=None,\n",
              "                                   punct={'!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
              "                                          ')', '*', '+', ',', '-', '.', '/', ':',\n",
              "                                          ';', '<', '=', '>', '?', '@', '[',\n",
              "                                          '\\\\', ']', '^', '_', '`', '{', '|', ...},\n",
              "                                   stopwords={'a', 'about', 'above', 'after',\n",
              "                                              'again', 'against', 'ain', 'all',\n",
              "                                              'am', 'an', 'and', 'any', 'are',\n",
              "                                              'aren', \"aren't\", 'as', 'at', 'be',\n",
              "                                              'because', 'been',...\n",
              "                                  tokenizer=<function identity at 0x7ff37b9bcb70>,\n",
              "                                  use_idf=True, vocabulary=None)),\n",
              "                 ('multilabel',\n",
              "                  OneVsRestClassifier(estimator=LogisticRegression(C=1,\n",
              "                                                                   class_weight='balanced',\n",
              "                                                                   dual=False,\n",
              "                                                                   fit_intercept=True,\n",
              "                                                                   intercept_scaling=1,\n",
              "                                                                   l1_ratio=None,\n",
              "                                                                   max_iter=4000,\n",
              "                                                                   multi_class='ovr',\n",
              "                                                                   n_jobs=None,\n",
              "                                                                   penalty='l2',\n",
              "                                                                   random_state=None,\n",
              "                                                                   solver='sag',\n",
              "                                                                   tol=0.0001,\n",
              "                                                                   verbose=0,\n",
              "                                                                   warm_start=False),\n",
              "                                      n_jobs=None))],\n",
              "          verbose=False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNILJVaP7fRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}